{"ast":null,"code":"export {};","map":{"version":3,"names":[],"sources":["C:\\Users\\Samue\\OneDrive\\Documents\\University\\Year 3\\Computing Project\\Code\\RevisionWebApp\\re-vision\\node_modules\\react-native-vision-camera\\src\\Frame.ts"],"sourcesContent":["import type { Orientation } from './Orientation'\nimport { PixelFormat } from './PixelFormat'\n\n/**\n * A single frame, as seen by the camera. This is backed by a C++ HostObject wrapping the native GPU buffer.\n * At a 4k resolution, a Frame can be 1.5MB in size.\n *\n * @example\n * ```ts\n * const frameProcessor = useFrameProcessor((frame) => {\n *   'worklet'\n *   console.log(`Frame: ${frame.width}x${frame.height} (${frame.pixelFormat})`)\n * }, [])\n * ```\n */\nexport interface Frame {\n  /**\n   * Whether the underlying buffer is still valid or not.\n   * A Frame is valid as long as your Frame Processor (or a `runAsync(..)` operation) is still running\n   */\n  isValid: boolean\n  /**\n   * Returns the width of the frame, in pixels.\n   */\n  width: number\n  /**\n   * Returns the height of the frame, in pixels.\n   */\n  height: number\n  /**\n   * Returns the amount of bytes per row.\n   */\n  bytesPerRow: number\n  /**\n   * Returns the number of planes this frame contains.\n   */\n  planesCount: number\n  /**\n   * Returns whether the Frame is mirrored (selfie camera) or not.\n   */\n  isMirrored: boolean\n  /**\n   * Returns the timestamp of the Frame relative to the host sytem's clock.\n   */\n  timestamp: number\n  /**\n   * Represents the orientation of the Frame.\n   *\n   * Some ML Models are trained for specific orientations, so they need to be taken into\n   * consideration when running a frame processor. See also: {@linkcode isMirrored}\n   */\n  orientation: Orientation\n  /**\n   * Represents the pixel-format of the Frame.\n   */\n  pixelFormat: PixelFormat\n\n  /**\n   * Get the underlying data of the Frame as a uint8 array buffer.\n   * The format of the buffer depends on the Frame's {@linkcode pixelFormat}.\n   *\n   * Note that Frames are allocated on the GPU, so calling `toArrayBuffer()` will copy from the GPU to the CPU.\n   *\n   * @example\n   * ```ts\n   * const frameProcessor = useFrameProcessor((frame) => {\n   *   'worklet'\n   *\n   *   if (frame.pixelFormat === 'rgb') {\n   *     const data = frame.toArrayBuffer()\n   *     console.log(`Pixel at 0,0: RGB(${data[0]}, ${data[1]}, ${data[2]})`)\n   *   }\n   * }, [])\n   * ```\n   */\n  toArrayBuffer(): Uint8Array\n  /**\n   * Returns a string representation of the frame.\n   * @example\n   * ```ts\n   * console.log(frame.toString()) // -> \"3840 x 2160 Frame\"\n   * ```\n   */\n  toString(): string\n}\n\n/** @internal */\nexport interface FrameInternal extends Frame {\n  /**\n   * Increment the Frame Buffer ref-count by one.\n   *\n   * This is a private API, do not use this.\n   * @internal\n   */\n  incrementRefCount(): void\n  /**\n   * Increment the Frame Buffer ref-count by one.\n   *\n   * This is a private API, do not use this.\n   * @internal\n   */\n  decrementRefCount(): void\n}\n"],"mappings":""},"metadata":{},"sourceType":"module","externalDependencies":[]}