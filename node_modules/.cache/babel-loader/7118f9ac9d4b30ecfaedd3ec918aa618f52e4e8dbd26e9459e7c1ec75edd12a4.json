{"ast":null,"code":"export {};","map":{"version":3,"names":[],"sources":["C:\\Users\\Samue\\OneDrive\\Documents\\University\\Year 3\\Computing Project\\Code\\RevisionWebApp\\re-vision\\node_modules\\react-native-vision-camera\\src\\CameraProps.ts"],"sourcesContent":["import type { ViewProps } from 'react-native'\nimport type { CameraDevice, CameraDeviceFormat, VideoStabilizationMode } from './CameraDevice'\nimport type { CameraRuntimeError } from './CameraError'\nimport { CodeScanner } from './CodeScanner'\nimport type { Frame } from './Frame'\nimport type { Orientation } from './Orientation'\n\nexport type FrameProcessor = {\n  frameProcessor: (frame: Frame) => void\n  type: 'frame-processor'\n}\n\n// TODO: Replace `enableHighQualityPhotos: boolean` in favor of `priorization: 'photo' | 'video'`\n// TODO: Use RCT_ENUM_PARSER for stuff like torch, videoStabilizationMode, and orientation\n// TODO: Use Photo HostObject for stuff like depthData, portraitEffects, etc.\n// TODO: Add RAW capture support\n\nexport interface CameraProps extends ViewProps {\n  /**\n   * The Camera Device to use.\n   *\n   * See the [Camera Devices](https://react-native-vision-camera.com/docs/guides/devices) section in the documentation for more information about Camera Devices.\n   *\n   * @example\n   * ```tsx\n   * const device = useCameraDevice('back')\n   *\n   * if (device == null) return <NoCameraErrorView />\n   * return (\n   *   <Camera\n   *     device={device}\n   *     isActive={true}\n   *     style={StyleSheet.absoluteFill}\n   *   />\n   * )\n   * ```\n   */\n  device: CameraDevice\n  /**\n   * Whether the Camera should actively stream video frames, or not. See the [documentation about the `isActive` prop](https://react-native-vision-camera.com/docs/guides/lifecycle#the-isactive-prop) for more information.\n   *\n   * This can be compared to a Video component, where `isActive` specifies whether the video is paused or not.\n   *\n   * > Note: If you fully unmount the `<Camera>` component instead of using `isActive={false}`, the Camera will take a bit longer to start again. In return, it will use less resources since the Camera will be completely destroyed when unmounted.\n   */\n  isActive: boolean\n\n  //#region Use-cases\n  /**\n   * Enables **photo capture** with the `takePhoto` function (see [\"Taking Photos\"](https://react-native-vision-camera.com/docs/guides/taking-photos))\n   */\n  photo?: boolean\n  /**\n   * Enables **video capture** with the `startRecording` function (see [\"Recording Videos\"](https://react-native-vision-camera.com/docs/guides/recording-videos))\n   */\n  video?: boolean\n  /**\n   * Enables **audio capture** for video recordings (see [\"Recording Videos\"](https://react-native-vision-camera.com/docs/guides/recording-videos))\n   */\n  audio?: boolean\n  /**\n   * Specifies the pixel format for the video pipeline.\n   *\n   * Make sure the given {@linkcode format} supports the given {@linkcode pixelFormat}.\n   *\n   * Affects:\n   * * {@linkcode frameProcessor}: The format of Frames from a [Frame Processor](https://react-native-vision-camera.com/docs/guides/frame-processors).\n   * While `'native'` and `'yuv'` are the most efficient formats, some ML models (such as TensorFlow Face Detection Models) require input Frames to be in RGB colorspace, otherwise they just output nonsense.\n   * * {@linkcode video}: The format of Frames streamed in the Video Pipeline. The format `'native'` is most efficient here.\n   *\n   * The following values are supported:\n   *\n   * - `native`: The hardware native GPU buffer format. This is the most efficient format. (`PRIVATE` on Android, sometimes YUV on iOS)\n   * - `yuv`: The YUV (Y'CbCr 4:2:0 or NV21, 8-bit) format, either video- or full-range, depending on hardware capabilities. This is the second most efficient format.\n   * - `rgb`: The RGB (RGB, RGBA or ABGRA, 8-bit) format. This is least efficient and requires explicit conversion.\n   *\n   * @default `native`\n   */\n  pixelFormat?: 'native' | 'yuv' | 'rgb'\n  //#endregion\n\n  //#region Common Props (torch, zoom)\n  /**\n   * Set the current torch mode.\n   *\n   * Make sure the given {@linkcode device} has a torch (see {@linkcode CameraDevice.hasTorch device.hasTorch}).\n   *\n   * @default \"off\"\n   */\n  torch?: 'off' | 'on'\n  /**\n   * Specifies the zoom factor of the current camera, in \"factor\"/scale.\n   *\n   * This value ranges from `minZoom` (e.g. `1`) to `maxZoom` (e.g. `128`). It is recommended to set this value\n   * to the CameraDevice's `neutralZoom` per default and let the user zoom out to the fish-eye (ultra-wide) camera\n   * on demand (if available)\n   *\n   * **Note:** Linearly increasing this value always appears logarithmic to the user.\n   *\n   * @default 1.0\n   */\n  zoom?: number\n  /**\n   * Enables or disables the native pinch to zoom gesture.\n   *\n   * If you want to implement a custom zoom gesture, see [the Zooming with Reanimated documentation](https://react-native-vision-camera.com/docs/guides/zooming).\n   *\n   * @default false\n   */\n  enableZoomGesture?: boolean\n  //#endregion\n\n  //#region Camera Controls\n  /**\n   * Specifies the Exposure bias of the current camera. A lower value means darker images, a higher value means brighter images.\n   *\n   * The Camera will still continue to auto-adjust exposure and focus, but will premultiply the exposure setting with the provided value here.\n   *\n   * This values ranges from {@linkcode CameraDevice.minExposure device.minExposure} to {@linkcode CameraDevice.maxExposure device.maxExposure}.\n   *\n   * The value between min- and max supported exposure is considered the default, neutral value.\n   */\n  exposure?: number\n  //#endregion\n\n  //#region Format/Preset selection\n  /**\n   * Selects a given format. By default, the best matching format is chosen. See {@linkcode CameraDeviceFormat}\n   *\n   * The format defines the possible values for properties like:\n   * - {@linkcode fps}: `format.minFps`...`format.maxFps`\n   * - {@linkcode videoHdr}: `format.supportsVideoHdr`\n   * - {@linkcode photoHdr}: `format.supportsPhotoHdr`\n   * - {@linkcode pixelFormat}: `format.pixelFormats``\n   * - {@linkcode enableDepthData}: `format.supportsDepthCapture``\n   * - {@linkcode videoStabilizationMode}: `format.videoStabilizationModes``\n   *\n   * In other words; {@linkcode enableDepthData} can only be set to true if {@linkcode CameraDeviceFormat.supportsDepthCapture format.supportsDepthCapture} is true.\n   */\n  format?: CameraDeviceFormat\n  /**\n   * Specifies the Preview's resize mode.\n   * * `\"cover\"`: Keep aspect ratio and fill entire parent view (centered).\n   * * `\"contain\"`: Keep aspect ratio and make sure the entire content is visible inside the parent view, even if it introduces additional blank areas (centered).\n   *\n   * @default \"cover\"\n   */\n  resizeMode?: 'cover' | 'contain'\n  /**\n   * Specify the frames per second this camera should stream frames at.\n   *\n   * Make sure the given {@linkcode format} can stream at the target {@linkcode fps} value (see {@linkcode CameraDeviceFormat.minFps format.minFps} and {@linkcode CameraDeviceFormat.maxFps format.maxFps}).\n   */\n  fps?: number\n  /**\n   * Enables or disables HDR Video Streaming for Preview, Video and Frame Processor via a 10-bit wide-color pixel format.\n   *\n   * Make sure the given {@linkcode format} supports HDR (see {@linkcode CameraDeviceFormat.supportsVideoHdr format.supportsVideoHdr}).\n   */\n  videoHdr?: boolean\n  /**\n   * Enables or disables HDR Photo Capture via a double capture routine that combines low- and high exposure photos.\n   *\n   * Make sure the given {@linkcode format} supports HDR (see {@linkcode CameraDeviceFormat.supportsPhotoHdr format.supportsPhotoHdr}).\n   */\n  photoHdr?: boolean\n  /**\n   * Enables or disables lossy buffer compression for the video stream.\n   * If you only use {@linkcode video} or a {@linkcode frameProcessor}, this\n   * can increase the efficiency and lower memory usage of the Camera.\n   *\n   * If buffer compression is enabled, the video pipeline will try to use a\n   * lossy-compressed pixel format instead of the normal one.\n   *\n   * If you use a {@linkcode frameProcessor}, you might need to change how pixels\n   * are read inside your native frame processor function as this is different\n   * from the usual `yuv` or `rgb` layout.\n   *\n   * If buffer compression is not available but this property is enabled, the normal\n   * pixel formats will be used and no error will be thrown.\n   *\n   * @platform iOS\n   * @default\n   * - true // if video={true} and frameProcessor={undefined}\n   * - false // otherwise\n   */\n  enableBufferCompression?: boolean\n  /**\n   * Enables or disables low-light boost on this camera device.\n   *\n   * Make sure the given {@linkcode device} supports low-light-boost (see {@linkcode CameraDevice.supportsLowLightBoost device.supportsLowLightBoost}).\n   */\n  lowLightBoost?: boolean\n  /**\n   * Specifies the video stabilization mode to use.\n   *\n   * Make sure the given {@linkcode format} supports the given {@linkcode videoStabilizationMode}.\n   */\n  videoStabilizationMode?: VideoStabilizationMode\n  //#endregion\n\n  /**\n   * Enables or disables depth data delivery for photo capture.\n   *\n   * Make sure the given {@linkcode format} supports depth data (see {@linkcode CameraDeviceFormat.supportsDepthCapture format.supportsDepthCapture}).\n   *\n   * @default false\n   */\n  enableDepthData?: boolean\n  /**\n   * A boolean specifying whether the photo render pipeline is prepared for portrait effects matte delivery.\n   *\n   * When enabling this, you must also set `enableDepthData` to `true`.\n   *\n   * @platform iOS 12.0+\n   * @default false\n   */\n  enablePortraitEffectsMatteDelivery?: boolean\n  /**\n   * Indicates whether the Camera should prepare the photo pipeline to provide maximum quality photos.\n   *\n   * This enables:\n   * * High Resolution Capture ([`isHighResolutionCaptureEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/1648721-ishighresolutioncaptureenabled))\n   * * Virtual Device fusion for greater detail ([`isVirtualDeviceConstituentPhotoDeliveryEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/3192189-isvirtualdeviceconstituentphotod))\n   * * Dual Device fusion for greater detail ([`isDualCameraDualPhotoDeliveryEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/2873917-isdualcameradualphotodeliveryena))\n   * * Sets the maximum quality prioritization to `.quality` ([`maxPhotoQualityPrioritization`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/3182995-maxphotoqualityprioritization))\n   *\n   * @default false\n   */\n  enableHighQualityPhotos?: boolean\n  /**\n   * If `true`, show a debug view to display the FPS of the Camera session.\n   * This is useful for debugging your Frame Processor's speed.\n   *\n   * @default false\n   */\n  enableFpsGraph?: boolean\n  /**\n   * Represents the orientation of all Camera Outputs (Photo, Video, and Frame Processor). If this value is not set, the device orientation is used.\n   */\n  orientation?: Orientation\n\n  //#region Events\n  /**\n   * Called when any kind of runtime error occured.\n   */\n  onError?: (error: CameraRuntimeError) => void\n  /**\n   * Called when the camera session was successfully initialized. This will get called everytime a new device is set.\n   */\n  onInitialized?: () => void\n  /**\n   * Called when the camera started the session (`isActive={true}`)\n   */\n  onStarted?: () => void\n  /**\n   * Called when the camera stopped the session (`isActive={false}`)\n   */\n  onStopped?: () => void\n  /**\n   * A worklet which will be called for every frame the Camera \"sees\".\n   *\n   * > See [the Frame Processors documentation](https://react-native-vision-camera.com/docs/guides/frame-processors) for more information\n   *\n   * @example\n   * ```tsx\n   * const frameProcessor = useFrameProcessor((frame) => {\n   *   'worklet'\n   *   const faces = scanFaces(frame)\n   *   console.log(`Faces: ${faces}`)\n   * }, [])\n   *\n   * return <Camera {...cameraProps} frameProcessor={frameProcessor} />\n   * ```\n   */\n  frameProcessor?: FrameProcessor\n  /**\n   * A CodeScanner that can detect QR-Codes or Barcodes using platform-native APIs.\n   *\n   * > See [the Code Scanner documentation](https://react-native-vision-camera.com/docs/guides/code-scanning) for more information\n   *\n   * @example\n   * ```tsx\n   * const codeScanner = useCodeScanner({\n   *   codeTypes: ['qr', 'ean-13'],\n   *   onCodeScanned: (codes) => {\n   *     console.log(`Scanned ${codes.length} codes!`)\n   *   }\n   * })\n   *\n   * return <Camera {...props} codeScanner={codeScanner} />\n   */\n  codeScanner?: CodeScanner\n  //#endregion\n}\n"],"mappings":""},"metadata":{},"sourceType":"module","externalDependencies":[]}